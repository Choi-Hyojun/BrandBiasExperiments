import json
import os
import time
from openai import OpenAI

# API Key ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ì§ì ‘ ìž…ë ¥)
# os.environ["OPENAI_API_KEY"] = "..."

BATCH_INFO_FILE = "batch_info.json"
BATCH_INPUT_FILE = "batch_input.jsonl"

def load_system_prompt():
    try:
        with open('system_prompt.txt', 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return "You are an expert in {DOMAIN}. Output JSON only."

def create_batch_file(fake_data, system_template):
    """Batch APIìš© JSONL íŒŒì¼ ìƒì„±"""
    tasks = []
    
    for domain, details in fake_data.items():
        categories = details.get("Product Category", [])
        for category in categories:
            # Custom IDì— ë„ë©”ì¸ê³¼ ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ì¸ì½”ë”© (êµ¬ë¶„ìž :: ì‚¬ìš©)
            custom_id = f"{domain}::{category}"
            
            prompt_content = system_template.format(
                DOMAIN=domain,
                CATEGORY=category
            )
            
            task = {
                "custom_id": custom_id,
                "method": "POST",
                "url": "/v1/chat/completions",
                "body": {
                    "model": "gpt-4o", # Batch APIëŠ” gpt-4o, gpt-4o-mini ë“± ì§€ì›
                    "messages": [
                        {"role": "system", "content": "You are a JSON generator. Output only valid JSON."},
                        {"role": "user", "content": prompt_content}
                    ],
                    "temperature": 0.7
                }
            }
            tasks.append(task)
            
    with open(BATCH_INPUT_FILE, 'w', encoding='utf-8') as f:
        for task in tasks:
            f.write(json.dumps(task) + '\n')
            
    print(f"âœ… Created batch input file with {len(tasks)} tasks: {BATCH_INPUT_FILE}")
    return len(tasks)

def submit_batch(client):
    """Batch íŒŒì¼ ì—…ë¡œë“œ ë° ìž‘ì—… ìƒì„±"""
    # 1. íŒŒì¼ ì—…ë¡œë“œ
    batch_input_file = client.files.create(
        file=open(BATCH_INPUT_FILE, "rb"),
        purpose="batch"
    )
    print(f"â¬†ï¸  Uploaded file ID: {batch_input_file.id}")

    # 2. Batch ìƒì„±
    batch_job = client.batches.create(
        input_file_id=batch_input_file.id,
        endpoint="/v1/chat/completions",
        completion_window="24h" # í˜„ìž¬ëŠ” 24hë§Œ ì§€ì› (50% í• ì¸)
    )
    
    print(f"ðŸš€ Batch job created! ID: {batch_job.id}")
    print("   (It may take up to 24 hours, but usually faster for small batches)")
    
    # ì •ë³´ ì €ìž¥
    info = {
        "batch_id": batch_job.id,
        "file_id": batch_input_file.id,
        "status": "submitted",
        "created_at": time.time()
    }
    with open(BATCH_INFO_FILE, 'w') as f:
        json.dump(info, f, indent=4)
        
    return batch_job.id

def check_and_retrieve_results(client):
    """Batch ìƒíƒœ í™•ì¸ ë° ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"""
    with open(BATCH_INFO_FILE, 'r') as f:
        info = json.load(f)
        
    batch_id = info['batch_id']
    batch_job = client.batches.retrieve(batch_id)
    
    print(f"ðŸ“Š Batch Status: {batch_job.status}")
    
    if batch_job.status == 'completed':
        print("â¬‡ï¸  Downloading results...")
        result_file_id = batch_job.output_file_id
        
        content = client.files.content(result_file_id).text
        
        # ê²°ê³¼ ì²˜ë¦¬ ë° ì €ìž¥
        save_results(content)
        
        # ì™„ë£Œ í‘œì‹œ (íŒŒì¼ ì‚­ì œ ë˜ëŠ” ìƒíƒœ ì—…ë°ì´íŠ¸)
        print("âœ… All files saved successfully!")
        os.remove(BATCH_INFO_FILE) # ìž‘ì—… ì™„ë£Œ í›„ ì •ë³´ íŒŒì¼ ì‚­ì œ
        
    elif batch_job.status in ['failed', 'expired', 'cancelled']:
        print(f"âŒ Batch failed: {batch_job.errors}")
    else:
        print("â³ Batch is still processing. Please try again later.")

def save_results(result_content):
    """ê²°ê³¼ JSONL íŒŒì‹± ë° íŒŒì¼ ì €ìž¥"""
    base_spec_dir = "Base_Specs"
    
    for line in result_content.strip().split('\n'):
        if not line: continue
        
        res = json.loads(line)
        custom_id = res['custom_id']
        domain, category = custom_id.split('::')
        
        # ì‘ë‹µ ë‚´ìš© ì¶”ì¶œ
        response_body = res['response']['body']
        if 'choices' in response_body:
            content = response_body['choices'][0]['message']['content']
            clean_json = content.replace("```json", "").replace("```", "").strip()
            
            try:
                spec_data = json.loads(clean_json)
                
                # ë””ë ‰í† ë¦¬ ìƒì„± ë° ì €ìž¥
                domain_dir = os.path.join(base_spec_dir, domain)
                os.makedirs(domain_dir, exist_ok=True)
                
                filename = f"{category.replace(' ', '_')}_base_spec.json"
                filepath = os.path.join(domain_dir, filename)
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(spec_data, f, indent=4)
                # print(f"   -> Saved {filepath}")
                
            except json.JSONDecodeError:
                print(f"âš ï¸ JSON Decode Error for {custom_id}")
        else:
            print(f"âš ï¸ Error in response for {custom_id}")

def main():
    client = OpenAI()
    
    # ì´ë¯¸ ì§„í–‰ ì¤‘ì¸ ë°°ì¹˜ê°€ ìžˆëŠ”ì§€ í™•ì¸
    if os.path.exists(BATCH_INFO_FILE):
        print("ðŸ”„ Found existing batch job info.")
        check_and_retrieve_results(client)
    else:
        print("ðŸ†• Starting new batch process...")
        # 1. ë°ì´í„° ë¡œë“œ
        with open('Fake_data.json', 'r', encoding='utf-8') as f:
            fake_data = json.load(f)
            
        system_template = load_system_prompt()
        
        # 2. ë°°ì¹˜ íŒŒì¼ ìƒì„±
        count = create_batch_file(fake_data, system_template)
        
        if count > 0:
            # 3. ë°°ì¹˜ ì œì¶œ
            submit_batch(client)
        else:
            print("No tasks to process.")

if __name__ == "__main__":
    main()